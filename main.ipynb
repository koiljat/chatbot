{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2024-02-01\",\n",
    "    deployment_name=\"gpt-35-turbo-16k\",\n",
    "    openai_api_key=api_key,\n",
    "    openai_api_type=endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our doucments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "document_paths = [\"content/resume.pdf\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for path in document_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    page = loader.load_and_split()\n",
    "    data.extend(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the documents into smaller chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the Vector Database and Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings()\n",
    "\n",
    "document_search = FAISS.from_documents(texts, embeddings)\n",
    "retriever = document_search.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the LLM Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"\"\n",
    "    Answer the question based on the context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    You are a helpful assistant that helps to give recruiters or manager answers on my capabilities.\n",
    "    You are to answer their questions that give them more insights on my skill set and past experiences\n",
    "    When the user refer You, it is refering to the candidate.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    Q:Where are you studying now?\n",
    "    \n",
    "    A:I study at NUS.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of the guide is to provide recruiters or managers with more insights on the candidate's skill set and past experiences.\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"What is the purpose of the guide?\"\n",
    "\n",
    "response = chain.invoke(sample_query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def similar_dist(query: str, vectorstore):\n",
    "    \"\"\"\n",
    "    Return Dataframe that consist of the text and the its distance from the query vector\n",
    "    \"\"\"\n",
    "\n",
    "    distance_list = []\n",
    "\n",
    "    similar_score = vectorstore.similarity_search_with_score(query)\n",
    "\n",
    "    for n in range(0, len(similar_score)):\n",
    "        text = vectorstore.similarity_search_with_score(query)[n][0].page_content\n",
    "        distance = vectorstore.similarity_search_with_score(query)[n][1]\n",
    "\n",
    "        distance_list.append((text, distance))\n",
    "\n",
    "    return pd.DataFrame(distance_list, columns=[\"text\", \"distance to query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>distance to query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and enhancing the interview selection process.</td>\n",
       "      <td>0.479918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>requirements gathering and documentation proce...</td>\n",
       "      <td>0.480015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efficiency.</td>\n",
       "      <td>0.491519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allow users to book reservations for various f...</td>\n",
       "      <td>0.491910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  distance to query\n",
       "0     and enhancing the interview selection process.           0.479918\n",
       "1  requirements gathering and documentation proce...           0.480015\n",
       "2                                        efficiency.           0.491519\n",
       "3  allow users to book reservations for various f...           0.491910"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function uses as similarity score to find the most similar text to the query\n",
    "# Can think of other methods to evaulate the similarity between the query and the text\n",
    "similar_dist(sample_query, document_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_question_answer(\n",
    "    query: str, vectorstore: FAISS = document_search, chain=chain\n",
    "):\n",
    "    \"\"\"\n",
    "    Return answer to the query\n",
    "    \"\"\"\n",
    "\n",
    "    response = chain.invoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(chat_history, user_input):\n",
    "\n",
    "    # input_docs = vectorstore.similarity_search(user_input,k=3)\n",
    "    # qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    # chain_response = qa_chain.run(input_documents=input_docs, question=user_input)\n",
    "\n",
    "    chain_response = source_question_answer(user_input)\n",
    "\n",
    "    print(chain_response)\n",
    "    response = \"\"\n",
    "    for letter in \"\".join(\n",
    "        chain_response\n",
    "    ):  # [bot_response[i:i+1] for i in range(0, len(bot_response), 1)]:\n",
    "        response += letter + \"\"\n",
    "\n",
    "        yield chat_history + [(user_input, response)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://d9595427e41f21083a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d9595427e41f21083a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the candidate's availability for an internship is as follows:\n",
      "\n",
      "1. Hologi c Business Analytics Intern: May 2023 - Nov 2023\n",
      "2. TikTok AI Data Operations Intern: Dec 2023 - Apr 2024\n",
      "3. AI Singapore AI Engineer Intern: May 2024 - Present\n",
      "4. NUS Business Analytics Centre Data Analyst: Oct 2023 - Feb 2024\n",
      "\n",
      "Please note that the availability mentioned above is based on the internship durations mentioned in the context.\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # Chatbot Demo\n",
    "    **Welcome!** Chat with my assistant to get answers on my skills and past experiences.\n",
    "    \n",
    "    ### Example Questions\n",
    "    - What previous experience do you have?\n",
    "    - What is your availability for internship?\n",
    "    \"\"\")\n",
    "    \n",
    "    examples = [\n",
    "        [\"What previous experience do you have?\"],\n",
    "        [\"What is your availability for internship?\"],\n",
    "    ]\n",
    "    \n",
    "    chatbot = gr.Chatbot()\n",
    "    message = gr.Textbox(placeholder=\"Type your message here...\", show_label=False)\n",
    "    message.submit(chat, [chatbot, message], chatbot)\n",
    "    gr.Examples(examples, inputs=message)\n",
    "\n",
    "\n",
    "demo.queue().launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
